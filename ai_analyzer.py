from __future__ import annotations

import os
import requests

from dotenv import load_dotenv

from stats_calculator import calculate_stock_stats

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")


def _normalize_model_name(model: str | None) -> str:
    if not model:
        return "gemini-1.5-flash"
    cleaned = model.strip()
    if cleaned.startswith("models/"):
        cleaned = cleaned.split("models/", 1)[1]
    return cleaned


GOOGLE_MODEL = _normalize_model_name(
    os.getenv("GOOGLE_MODEL", "gemini-1.5-flash")
)
GOOGLE_FALLBACK_MODEL = _normalize_model_name(
    os.getenv("GOOGLE_FALLBACK_MODEL", "gemini-1.5-flash")
)

# ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· Google AI Studio (Gemini)
def generate_ai_analysis(ticker, start_date, end_date):

    stats = None
    try:
        stats, _ = calculate_stock_stats(ticker, start_date, end_date)
        if not stats:
            return "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°"

        if not GOOGLE_API_KEY:
            return fallback_analysis(stats, ticker)

        prompt = (
            "Ð”Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¹ (3-4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ) Ð°Ð½Ð°Ð»Ð¸Ð· Ð°ÐºÑ†Ð¸Ð¸ Ð·Ð° ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´. "
            "ÐÐµ Ð¿Ð¸ÑˆÐ¸ Ð²ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ð¹. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: Ñ‚Ñ€ÐµÐ½Ð´, Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ/Ñ€Ð¸ÑÐºÐ¸, "
            "Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ, Ð²Ñ‹Ð²Ð¾Ð´."
            f"\nÐ¢Ð¸ÐºÐµÑ€: {ticker}\nÐŸÐµÑ€Ð¸Ð¾Ð´: {start_date} - {end_date}"
            f"\nÐ¡Ñ‚Ð°Ñ€Ñ‚: ${stats['start_price']:.2f}, ÐºÐ¾Ð½ÐµÑ†: "
            f"${stats['end_price']:.2f}"
            f"\nÐ˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ: {stats['price_change_percent']:.1f}%"
            f"\nÐœÐ¸Ð½/Ð¼Ð°ÐºÑ: ${stats['min_price']:.2f} / "
            f"${stats['max_price']:.2f}"
            f"\nÐ¡Ñ€ÐµÐ´Ð½ÑÑ: ${stats['average_price']:.2f}, Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: "
            f"${stats['volatility']:.2f}"
            f"\nÐžÐ±ÑŠÐµÐ¼: {stats['total_volume']:,.0f}, Ð´Ð½ÐµÐ¹: "
            f"{stats['days_count']}"
        )

        def call_model(model_name: str, max_tokens: int = 160):
            api_url = (
                f"https://generativelanguage.googleapis.com/v1beta/models/"
                f"{model_name}:generateContent?key={GOOGLE_API_KEY}"
            )
            payload = {
                "contents": [
                    {"role": "user", "parts": [{"text": prompt}]}
                ],
                "generationConfig": {
                    "temperature": 0.6,
                    "maxOutputTokens": max_tokens,
                    "responseModalities": ["TEXT"],
                },
            }
            try:
                resp = requests.post(api_url, json=payload, timeout=30)
                if resp.status_code == 200:
                    result = resp.json()
                    text = ""
                    content = result.get("candidates", [{}])[0].get(
                        "content",
                        {},
                    )
                    for part in content.get("parts", []):
                        if "text" in part:
                            text += part["text"]
                    if text:
                        return text
                    # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð´Ð»Ñ Ð´ÐµÐ±Ð°Ð³Ð°
                    if result.get("candidates"):
                        finish = result["candidates"][0].get("finishReason")
                        print(
                            f"ÐŸÑƒÑÑ‚Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_name}, "
                            f"finishReason={finish}"
                        )
                    return None
                else:
                    print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Google AI API ({model_name}): {resp.text}")
                    return None
            except Exception as err:
                print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_name}: {err}")
                return None

        # ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        text = call_model(GOOGLE_MODEL, max_tokens=512)
        if text:
            return format_ai_response(text)

        # Ð ÐµÑ‚Ñ€Ð°Ð¹ Ð½Ð° fallback-Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ flash),
        # ÐµÑÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°/Ð¿ÑƒÑÑ‚Ð°Ñ
        if GOOGLE_FALLBACK_MODEL and GOOGLE_FALLBACK_MODEL != GOOGLE_MODEL:
            text = call_model(GOOGLE_FALLBACK_MODEL, max_tokens=384)
            if text:
                return format_ai_response(text)

        return fallback_analysis(stats, ticker)

    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° AI-Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {e}")
        if stats:
            return fallback_analysis(stats, ticker)
        return "âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÑƒ"


def format_ai_response(text):
    cleaned_text = text.strip()
    if '```' in cleaned_text:
        cleaned_text = cleaned_text.replace('```', '').strip()

    return f"AI-ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ°:\n\n{cleaned_text}"

# Ð—Ð°Ð¿Ð°ÑÐ½Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ñ… ÐµÑÐ»Ð¸ AI Ð½Ðµ ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°Ð»
def fallback_analysis(stats, ticker):

    analysis = "ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° (Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°Ñ…):\n\n"

    # ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ñ€ÐµÐ½Ð´Ð°
    change_percent = stats['price_change_percent']
    if change_percent > 10:
        analysis += (
            f"Ð¡Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ñ€ÐµÐ½Ð´ - Ð°ÐºÑ†Ð¸Ñ {ticker} Ð²Ñ‹Ñ€Ð¾ÑÐ»Ð° Ð½Ð° "
            f"{change_percent:.1f}%, Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÑ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½ÑƒÑŽ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÑƒ. "
        )
    elif change_percent > 2:
        analysis += (
            "â†—ï¸ Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ñ‹Ð¹ Ñ€Ð¾ÑÑ‚ - "
            f"{ticker} Ð¿Ð¾ÐºÐ°Ð·Ð°Ð»Ð° Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½ÑƒÑŽ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÑƒ Ñ Ñ€Ð¾ÑÑ‚Ð¾Ð¼ "
            f"{change_percent:.1f}%. "
        )
    elif change_percent > -2:
        analysis += (
            "âž¡ï¸ Ð‘Ð¾ÐºÐ¾Ð²Ð¾Ð¹ Ñ‚Ñ€ÐµÐ½Ð´ - Ñ†ÐµÐ½Ð° ÐºÐ¾Ð»ÐµÐ±Ð°Ð»Ð°ÑÑŒ Ð² ÑƒÐ·ÐºÐ¾Ð¼ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ðµ "
            f"({change_percent:.1f}%). "
        )
    elif change_percent > -10:
        analysis += (
            "â†˜ï¸ ÐšÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ñ - "
            f"{ticker} ÑÐ½Ð¸Ð·Ð¸Ð»Ð°ÑÑŒ Ð½Ð° {abs(change_percent):.1f}%, "
            "Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸ÐµÐ¹. "
        )
    else:
        analysis += (
            "ðŸ“‰ Ð¡Ð¸Ð»ÑŒÐ½Ð¾Ðµ Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ - Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð½Ð° "
            f"{abs(change_percent):.1f}% Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ. "
        )

    volatility = stats['volatility']
    if volatility > 8:
        analysis += "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑƒÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð½Ð° Ð¿Ð¾Ð²Ñ‹ÑˆÐµÐ½Ð½Ñ‹Ðµ Ñ€Ð¸ÑÐºÐ¸. "
    elif volatility > 3:
        analysis += (
            "Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð°Ñ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÐµÑ‚ Ñ€Ñ‹Ð½Ð¾Ñ‡Ð½Ñ‹Ð¼ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸ÑÐ¼. "
        )
    else:
        analysis += "ÐÐ¸Ð·ÐºÐ°Ñ Ð²Ð¾Ð»Ð°Ñ‚Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ Ð¾ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸. "

    avg_volume = stats['total_volume'] / stats['days_count']
    if avg_volume > 50000000:
        analysis += "Ð’Ñ‹ÑÐ¾ÐºÐ¸Ðµ Ð¾Ð±ÑŠÐµÐ¼Ñ‹ Ñ‚Ð¾Ñ€Ð³Ð¾Ð² Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´Ð°ÑŽÑ‚ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑ Ð¸Ð½Ð²ÐµÑÑ‚Ð¾Ñ€Ð¾Ð². "
    else:
        analysis += "ÐžÐ±ÑŠÐµÐ¼Ñ‹ Ñ‚Ð¾Ñ€Ð³Ð¾Ð² Ð² Ñ€Ð°Ð¼ÐºÐ°Ñ… ÑÑ€ÐµÐ´Ð½Ð¸Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹. "

    if change_percent > 5 and volatility < 5:
        analysis += "ðŸ“Š Ð’Ñ‹Ð²Ð¾Ð´: ÐŸÐµÑ€ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼Ñ‹Ð¼Ð¸ Ñ€Ð¸ÑÐºÐ°Ð¼Ð¸."
    elif change_percent < -5:
        analysis += (
            "ðŸ“Š Ð’Ñ‹Ð²Ð¾Ð´: Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð¾ÑÑ‚Ð¾Ñ€Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¸Ð·-Ð·Ð° Ð½ÐµÐ³Ð°Ñ‚Ð¸Ð²Ð½Ð¾Ð¹ Ð´Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ¸."
        )
    else:
        analysis += "ðŸ“Š Ð’Ñ‹Ð²Ð¾Ð´: ÐÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ð°Ñ ÐºÐ°Ñ€Ñ‚Ð¸Ð½Ð°, Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³."

    return analysis
